{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUExP86AP9GCRf+PxDDoHq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rakshit9/Generative-AI/blob/main/ThinkFlow_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "TDRWh8LW-wrC"
      },
      "outputs": [],
      "source": [
        "!pip -q install \"langchain>=0.3.0\" \"langgraph>=0.2.0\" \"langchain-openai>=0.2.0\" \"python-dotenv>=1.0.1\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S-7SwIF4x8Mc"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "from langchain_openai import ChatOpenAI"
      ],
      "metadata": {
        "id": "bcid_ve4zetk"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define state\n",
        "class State(dict):\n",
        "  topic:str\n",
        "  retrieved:str\n",
        "  summary:str\n",
        "  feedback:str"
      ],
      "metadata": {
        "id": "JPeUf0T3zzzY"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inititalize LLM\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
      ],
      "metadata": {
        "id": "8rfg0lF50EQs"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NODE 1 : Retrieval\n",
        "def retrieve_info(state: State):\n",
        "  topic = state[\"topic\"]\n",
        "  state[\"retrieved\"] = f\"Top search results and notes about {topic}. (pretend web data)\"\n",
        "  print(f\"Retrieved context for: {topic}\")\n",
        "  return state"
      ],
      "metadata": {
        "id": "wQcckk3Q03Ng"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary(state: State):\n",
        "    context = state[\"retrieved\"]\n",
        "    prompt = f\"Summarize this information clearly and concisely:\\n\\n{context}\"\n",
        "    response = llm.invoke(prompt)\n",
        "    state[\"summary\"] = response.content\n",
        "    print(\"Generated summary ‚úÖ\")\n",
        "    return state"
      ],
      "metadata": {
        "id": "5g8RIbli1dBs"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----- Node 3: Evaluate Summary -----\n",
        "def evaluate_summary(state: State):\n",
        "    summary = state[\"summary\"]\n",
        "    prompt = f\"Critique this summary for clarity and accuracy. Give a short feedback:\\n\\n{summary}\"\n",
        "    response = llm.invoke(prompt)\n",
        "    state[\"feedback\"] = response.content\n",
        "    print(\"Evaluated summary üîç\")\n",
        "    return state"
      ],
      "metadata": {
        "id": "mfG-kHwW1Wx7"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Added graph Node\n",
        "graph = StateGraph(State)\n",
        "graph.add_node(\"retrieve\", retrieve_info)\n",
        "graph.add_node(\"summarize\", generate_summary)\n",
        "graph.add_node(\"evaluate\", evaluate_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VV1I9Oid0Px4",
        "outputId": "65b16560-b465-4cf5-a9b7-a4f8e9074322"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7ef94bc87350>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph.set_entry_point(\"retrieve\")\n",
        "graph.add_edge(\"retrieve\", \"summarize\")\n",
        "graph.add_edge(\"summarize\", \"evaluate\")\n",
        "graph.set_finish_point(\"evaluate\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xan4Fnis0x1S",
        "outputId": "da007309-7cd8-4e8f-9cb4-b71da930c9f1"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7ef94bc87350>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "app = graph.compile()"
      ],
      "metadata": {
        "id": "mwtthR2a1lVV"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----- Run the Agent -----\n",
        "topic = \"Impact of AI on healthcare\"\n",
        "result = app.invoke({\"topic\": topic})\n",
        "print(\"\\n--- FINAL OUTPUT ---\")\n",
        "print(f\"Topic: {result['topic']}\")\n",
        "print(f\"Retrieved: {result['retrieved']}\")\n",
        "print(f\"Summary: {result['summary']}\")\n",
        "print(f\"Feedback: {result['feedback']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hO1TDV8L1lmP",
        "outputId": "33423a46-7125-445e-b5a8-a6c717fdd504"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved context for: Impact of AI on healthcare\n",
            "Generated summary ‚úÖ\n",
            "Evaluated summary üîç\n",
            "\n",
            "--- FINAL OUTPUT ---\n",
            "Topic: Impact of AI on healthcare\n",
            "Retrieved: Top search results and notes about Impact of AI on healthcare. (pretend web data)\n",
            "Summary: Top search results show that AI is revolutionizing healthcare by improving diagnosis accuracy, treatment effectiveness, and patient outcomes. AI technologies such as machine learning and natural language processing are being used to analyze medical data, predict disease progression, and personalize treatment plans. However, concerns about data privacy, bias in algorithms, and job displacement are also being raised.\n",
            "Feedback: This summary effectively highlights the positive impact of AI in healthcare, such as improving diagnosis accuracy and treatment effectiveness. It also mentions potential concerns like data privacy and bias in algorithms. However, it could benefit from providing more specific examples or statistics to further illustrate the points made. Overall, a clear and informative summary.\n"
          ]
        }
      ]
    }
  ]
}