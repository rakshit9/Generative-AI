{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqZvs9Q0MkLWuAlm8sytJF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rakshit9/Generative-AI/blob/main/LangGraph_Article_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip -q install \"langchain>=0.3.0\" \"langgraph>=0.2.0\" \"langchain-openai>=0.2.0\" \"python-dotenv>=1.0.1\""
      ],
      "metadata": {
        "id": "Nhjy044L7Pry"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "5ZGyoQFK597x"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass, field\n",
        "from typing import List, Dict\n",
        "from openai import OpenAI\n",
        "\n",
        "@dataclass\n",
        "class ArticleState:\n",
        "    topic: str = \"\"\n",
        "    notes: list = field(default_factory=list)\n",
        "    outline: list = field(default_factory=list)\n",
        "    sections: list = field(default_factory=list)\n",
        "    article: str = \"\"\n",
        "\n",
        "out_dict = app.invoke({\"topic\": \"LangGraph 101\", \"notes\": [\"graphs\", \"state\", \"nodes\"]})\n",
        "out = ArticleState(**out_dict)   # now you can do out.outline, out.article\n",
        "def llm(prompt: str) -> str:\n",
        "    \"\"\"Simple LLM helper (stub if no key).\"\"\"\n",
        "    if not os.getenv(\"OPENAI_API_KEY\"):\n",
        "        # fake LLM output just to visualize the flow\n",
        "        return f\"[stub output for prompt → {prompt[:100]}...]\"\n",
        "    client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\":\"user\",\"content\":prompt}],\n",
        "        temperature=0.4,\n",
        "        max_tokens=400,\n",
        "    )\n",
        "    return resp.choices[0].message.content.strip()"
      ],
      "metadata": {
        "id": "fp9JhWqqy5n6"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "def node_outline(state: ArticleState) -> ArticleState:\n",
        "    prompt = f\"Create 3–5 section titles for an article about '{state.topic}' using these notes:\\n{state.notes}\"\n",
        "    raw = llm(prompt)\n",
        "    state.outline = [ln.strip(\"-• \").strip() for ln in raw.splitlines() if ln.strip()][:5]\n",
        "    return state\n",
        "\n",
        "def node_sections(state: ArticleState) -> ArticleState:\n",
        "    sections = []\n",
        "    for title in state.outline:\n",
        "        prompt = f\"Write 2 short paragraphs for section '{title}' about {state.topic}.\"\n",
        "        body = llm(prompt)\n",
        "        sections.append({\"title\": title, \"body\": body})\n",
        "    state.sections = sections\n",
        "    return state\n",
        "\n",
        "def node_assemble(state: ArticleState) -> ArticleState:\n",
        "    article_parts = [f\"# {state.topic}\"]\n",
        "    for s in state.sections:\n",
        "        article_parts.append(f\"## {s['title']}\\n{s['body']}\")\n",
        "    state.article = \"\\n\\n\".join(article_parts)\n",
        "    return state\n"
      ],
      "metadata": {
        "id": "sI6_MnTp-yt4"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Minimal LangGraph demo using dict state (no attribute access)\n",
        "\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# --- \"LLM\" stub (replace with your real call if you have a key) ---\n",
        "def llm(prompt: str) -> str:\n",
        "    return f\"[stub] {prompt[:120]}...\"\n",
        "\n",
        "# --- Nodes expect/return dicts ---\n",
        "def node_make_outline(state: dict) -> dict:\n",
        "    raw = llm(f\"Create 3–5 section titles for '{state['topic']}' using notes: {state['notes']}\")\n",
        "    outline = [ln.strip(\"-• \").strip() for ln in raw.splitlines() if ln.strip()][:5]\n",
        "    state[\"outline\"] = outline if outline else [\"Introduction\", \"Key Ideas\", \"Conclusion\"]\n",
        "    return state\n",
        "\n",
        "def node_draft_sections(state: dict) -> dict:\n",
        "    sections = []\n",
        "    for title in state[\"outline\"]:\n",
        "        body = llm(f\"Write 2 short paragraphs for section '{title}' about {state['topic']}.\")\n",
        "        sections.append({\"title\": title, \"body\": body})\n",
        "    state[\"sections\"] = sections\n",
        "    return state\n",
        "\n",
        "def node_assemble_article(state: dict) -> dict:\n",
        "    parts = [f\"# {state['topic']}\"]\n",
        "    for s in state[\"sections\"]:\n",
        "        parts.append(f\"## {s['title']}\\n{s['body']}\")\n",
        "    state[\"article\"] = \"\\n\\n\".join(parts)\n",
        "    return state\n",
        "\n",
        "# --- Build graph ---\n",
        "graph = StateGraph(dict)\n",
        "graph.add_node(\"make_outline\", node_make_outline)\n",
        "graph.add_node(\"draft_sections\", node_draft_sections)\n",
        "graph.add_node(\"assemble_article\", node_assemble_article)\n",
        "\n",
        "graph.set_entry_point(\"make_outline\")\n",
        "graph.add_edge(\"make_outline\", \"draft_sections\")\n",
        "graph.add_edge(\"draft_sections\", \"assemble_article\")\n",
        "graph.add_edge(\"assemble_article\", END)\n",
        "\n",
        "app = graph.compile()\n",
        "\n",
        "# --- Run with dict input ---\n",
        "state_in = {\n",
        "    \"topic\": \"How LangGraph Helps Build AI Agents\",\n",
        "    \"notes\": [\n",
        "        \"Workflows as graphs (nodes + edges).\",\n",
        "        \"Single state object flows through nodes.\",\n",
        "        \"Great for multi-step LLM apps.\",\n",
        "    ],\n",
        "}\n",
        "result = app.invoke(state_in)\n",
        "\n",
        "# --- Access dict keys (not attributes) ---\n",
        "print(\"OK! Outline:\", result[\"outline\"][:5])\n",
        "print(\"\\nARTICLE PREVIEW:\\n\", result[\"article\"][:600])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecr_QTzc-1F4",
        "outputId": "46bcd7d8-05af-4188-c20b-904e65d15b0e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK! Outline: [\"[stub] Create 3–5 section titles for 'How LangGraph Helps Build AI Agents' using notes: ['Workflows as graphs (nodes + edges).'...\"]\n",
            "\n",
            "ARTICLE PREVIEW:\n",
            " # How LangGraph Helps Build AI Agents\n",
            "\n",
            "## [stub] Create 3–5 section titles for 'How LangGraph Helps Build AI Agents' using notes: ['Workflows as graphs (nodes + edges).'...\n",
            "[stub] Write 2 short paragraphs for section '[stub] Create 3–5 section titles for 'How LangGraph Helps Build AI Agents' using n...\n"
          ]
        }
      ]
    }
  ]
}